{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "from reader import InHospitalMortalityReader, PhenotypingReader, LengthOfStayReader, DecompensationReader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/channel_info.json') as f:\n",
    "    series_channel_info = json.load(f)\n",
    "\n",
    "with open('resources/discretizer_config.json') as f:\n",
    "    series_config = json.load(f)\n",
    "    id_to_channel = series_config['id_to_channel']\n",
    "    is_categorical_channel = series_config['is_categorical_channel']\n",
    "    normal_values = series_config['normal_values']\n",
    "    possible_values = series_config['possible_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chunk(reader, chunk_size):\n",
    "    data = {}\n",
    "    for i in range(chunk_size):\n",
    "        ret = reader.read_next()\n",
    "        for k, v in ret.items():\n",
    "            if k not in data:\n",
    "                data[k] = []\n",
    "            data[k].append(v)\n",
    "    data[\"header\"] = data[\"header\"][0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21139 21139 21139 21139\n"
     ]
    }
   ],
   "source": [
    "period_length = 48\n",
    "path = '/data1/yzh/codebase/data/MIMIC-III/mortality/'\n",
    "\n",
    "data_all = []\n",
    "mask_all = []\n",
    "label_all = []\n",
    "name_all = []\n",
    "for mode in ['train', 'val', 'test']:\n",
    "    reader = InHospitalMortalityReader(dataset_dir=os.path.join(path, 'train' if mode != 'test' else 'test'),\n",
    "            listfile=os.path.join(path, mode + '_listfile.csv'), period_length=period_length)\n",
    "    N = reader.get_number_of_examples()\n",
    "    ret = read_chunk(reader, N)\n",
    "    data = ret[\"X\"]\n",
    "    ts = ret[\"t\"]\n",
    "    labels = ret[\"y\"]\n",
    "    names = ret[\"name\"]\n",
    "    label_all += labels\n",
    "    name_all += names\n",
    "    for patient, name in zip(data, names):\n",
    "        data_patient = np.zeros(shape=(len(id_to_channel), period_length), dtype=np.float32)\n",
    "        mask_patient = np.zeros(shape=(len(id_to_channel), period_length), dtype=np.float32)\n",
    "        last_time = -1\n",
    "        for row in patient:\n",
    "            time = int(float(row[0]))\n",
    "            if time == period_length:\n",
    "                time -= 1\n",
    "            if time > period_length:\n",
    "                raise ValueError('This should not happen')\n",
    "                break\n",
    "            for index in range(len(row) - 1):\n",
    "                value = row[index + 1]\n",
    "                if value == '':\n",
    "                    # continue\n",
    "                    if mask_patient[index, time] == 0 and time - last_time > 0:\n",
    "                        if last_time >= 0:\n",
    "                            data_patient[index, last_time + 1:time + 1] = data_patient[index, last_time]\n",
    "                        else:\n",
    "                            if is_categorical_channel[id_to_channel[index]]:\n",
    "                                data_patient[index, last_time + 1:time + 1] = series_channel_info[id_to_channel[index]]['values'][normal_values[id_to_channel[index]]]\n",
    "                            else:\n",
    "                                data_patient[index, last_time + 1:time + 1] = float(normal_values[id_to_channel[index]])\n",
    "                else:\n",
    "                    mask_patient[index, time] = 1\n",
    "                    if is_categorical_channel[id_to_channel[index]]:\n",
    "                        data_patient[index, time] = series_channel_info[id_to_channel[index]]['values'][value]\n",
    "                    else:\n",
    "                        data_patient[index, time] = float(value)\n",
    "            last_time = time\n",
    "        if last_time < period_length - 1:\n",
    "            data_patient[:, last_time + 1:period_length] = data_patient[:, last_time, None]\n",
    "        data_all.append(data_patient.transpose(-1, -2))\n",
    "        mask_all.append(mask_patient.transpose(-1, -2))\n",
    "print(len(data_all), len(mask_all), len(label_all), len(name_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13354037267080746 61.46690821598523 0.5394059277377888\n",
      " 3.119367646871375 5.290858060882255 11.618071512938903 3.1806345816977584\n",
      " 143.21973519841134 86.29870307167235 168.72015948168453 78.73721156458411\n",
      " 97.69931626649706 19.29791803628463 120.31002625862565 37.03954583770163\n",
      " 83.27327296371479 7.28222605621633] [0.3401578185750751 250.4033844396291 0.20066273178085373\n",
      " 1.262167663202079 1.4043288333340955 3.908595655788102 1.8973968540861121\n",
      " 69.22505471875131 19.16908521820205 15.020152083998523 154.81962785121664\n",
      " 1031.0258674132324 6.63096314003484 25.231333122285367 9.536494024362197\n",
      " 26.057987256006786 2.217912317350937]\n"
     ]
    }
   ],
   "source": [
    "data_all = np.array(data_all)\n",
    "mask_all = np.array(mask_all)\n",
    "data_all_concat = np.concatenate(data_all, axis=0)\n",
    "x_masked = np.ma.masked_array(data_all_concat, np.concatenate(mask_all, axis=0) == 0)\n",
    "mean = np.mean(x_masked, 0)\n",
    "std = np.std(x_masked, 0)\n",
    "print(mean, std)\n",
    "data_normalized = np.where(mask_all == 1, (data_all - mean.reshape(1, 1, -1)) / std.reshape(1, 1, -1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump((data_all.tolist(), label_all, np.array(), mask_all.tolist(), name_all), open('mortality.pkl', 'wb'))\n",
    "pickle.dump((data_normalized.tolist(), label_all, mask_all.tolist(), name_all), open('data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Rate: 0.43294860164606075\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "cnt1 = 0\n",
    "for i in range(len(mask_all)):\n",
    "    for j in range(len(mask_all[i])):\n",
    "        cnt += sum(mask_all[i][j])\n",
    "        cnt1 += len(mask_all[i][j])\n",
    "print('Observed Rate:', cnt / cnt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13231467902928237"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(label_all) / len(label_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21139 1014672 48 48\n"
     ]
    }
   ],
   "source": [
    "lens = []\n",
    "for i in range(len(data_normalized)):\n",
    "    lens.append(len(data_normalized[i]))\n",
    "print(len(data_normalized), sum(lens), min(lens), max(lens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
